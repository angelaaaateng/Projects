{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System - Marketplace Matching\n",
    "\n",
    "In this notebook, we will: \n",
    "- Clean textual data from user-input verbatim posts\n",
    "- Use a Word2Vec model to calculate document similarities \n",
    "- Sort the most similar user input to our training data in order to recommend similar products \n",
    "- Save this model in a format that allows us to refresh the testing data\n",
    "\n",
    "The goal of this project is to create a recommender system to help Pangeans find the right \"project\" for them, given their profile information. Here, we are using legacy data that is from Pangea V2, when Pangeans were allowed to post services and requests, as well as purchase items on the platform. We are using the User-Inputted Titles to suggest similar services, or in V3, similar \"projects\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angelateng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''Importing Libraries'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "from pandas import DataFrame\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords') ###\n",
    "\n",
    "import gensim \n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from operator import add\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import operator\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Loading the model'''\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''Vectorize and store existing titles in legacy Pangea database'''\n",
    "def vectorize_and_store_existing_titles(): \n",
    "    raw = pd.read_csv(\"allPostData.csv\", header=0);\n",
    "    titles = raw['title'];\n",
    "    post_titles = [title for title in titles];\n",
    "    post_titles = set(post_titles);\n",
    "    tokens = [[word for word in title.lower().split()] for title in post_titles];\n",
    "    clean_words = [[word for word in title if word.isalpha()] for title in tokens];\n",
    "    stoplist = set(stopwords.words('english'));\n",
    "    titles_nostopwords = [[word for word in title if word not in stoplist] for title in clean_words];   \n",
    "    filtered_word_list = [[word for word in title if word in model.vocab] for title in titles_nostopwords];\n",
    "    dictionary = dict(zip(post_titles, filtered_word_list))\n",
    "    vectorized_titles = pd.DataFrame(columns=[\"Titles\", \"Vectors\"])\n",
    "    for title in post_titles: \n",
    "        word_vecs = [model[word] for word in dictionary[title]]\n",
    "        if len(word_vecs) == 0:\n",
    "            title_vec = [np.zeros(300)]\n",
    "        else: \n",
    "            title_vec = normalize(sum(word_vecs).reshape(1, -1))\n",
    "        vectorized_titles = vectorized_titles.append({'Titles': title, 'Vectors': title_vec}, ignore_index=True)\n",
    "    vectorized_titles.to_pickle(\"/Users/angelateng/Dropbox/AMBER/SharpestMinds/vectorized_titles.pkl\")\n",
    "    return(vectorized_titles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Corporate Finance Tutor</td>\n",
       "      <td>[[0.009595259, 0.0074430513, -0.050515227, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R Tutoring</td>\n",
       "      <td>[[-0.0508224, 0.11041136, -0.016052296, 0.1061...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Help Setting up for Farmers Market Sun</td>\n",
       "      <td>[[0.0017549094, 0.07764145, -0.04477678, 0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bak-Tang-Wiesenfeld Model Appl.</td>\n",
       "      <td>[[0.07684814, 0.05254751, 0.03842407, 0.088479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feedback (re: Pangea)</td>\n",
       "      <td>[[-0.06494846, -0.00715124, -0.04504936, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recital Poster</td>\n",
       "      <td>[[0.057445057, 0.024767978, 0.0071285986, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beautycounter Social</td>\n",
       "      <td>[[0.039335, -0.038753696, -0.049023423, 0.0647...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Solidworks Help</td>\n",
       "      <td>[[0.011597187, 0.06816306, -0.061062742, 0.136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Homecooked Dinner</td>\n",
       "      <td>[[-0.046437792, -0.011173413, -0.012645033, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Food delivery!</td>\n",
       "      <td>[[-0.06801747, 0.06180082, -0.062166505, 0.133...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Video making lessons</td>\n",
       "      <td>[[0.017601628, 0.041898996, 0.046152107, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pokemon lets go</td>\n",
       "      <td>[[0.008599127, 0.025929207, 0.04041995, 0.0909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Behavioral Interview Prep</td>\n",
       "      <td>[[-0.03956067, 0.072352774, -0.069752164, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Farm Fresh Meal Prep!</td>\n",
       "      <td>[[-0.032631777, 0.014317139, 0.014599571, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Personal Trainer</td>\n",
       "      <td>[[0.02932334, -0.014871498, 0.005665332, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Film shoot participants!</td>\n",
       "      <td>[[0.032354895, 0.009640244, -0.012234643, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dogsitting</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Life Coach</td>\n",
       "      <td>[[-0.030054724, 0.043134633, 0.07173603, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cs hw</td>\n",
       "      <td>[[-0.09039003, 0.042158194, 0.058458764, 0.034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Metal machine</td>\n",
       "      <td>[[0.016601164, 0.030331235, -0.025981957, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BONEYARDS</td>\n",
       "      <td>[[0.05402433, 0.117187105, 0.023383666, 0.0631...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Translation</td>\n",
       "      <td>[[-0.014843704, -0.0070974, -0.005008736, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lamp</td>\n",
       "      <td>[[-0.00524103, 0.06696872, -0.020381782, 0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ID Friend</td>\n",
       "      <td>[[0.08986307, -0.08230449, 0.037840683, 0.0773...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Photography</td>\n",
       "      <td>[[0.0005714418, 0.017823197, -0.026233276, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Jeenne</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bike lessons</td>\n",
       "      <td>[[0.020154754, 0.020881988, 0.053399708, 0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Your man</td>\n",
       "      <td>[[0.14116225, 0.056633953, 0.0150037715, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Foam Models</td>\n",
       "      <td>[[0.0032934858, 0.040808346, 0.016673272, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Social Media Management</td>\n",
       "      <td>[[0.008659906, -0.0006811162, -0.09584278, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Zero Waste Pop Up Shop</td>\n",
       "      <td>[[-0.0057765376, 0.05752307, 0.058385674, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>Selling Galaxy Note 2</td>\n",
       "      <td>[[0.022602776, 0.12781008, -0.06594746, -0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>French tutoring</td>\n",
       "      <td>[[0.011164687, 0.07357873, 0.06452894, 0.15856...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Board Games! (Teaching)</td>\n",
       "      <td>[[-0.058998547, -0.10603793, -0.0065775407, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>SAS / SQL Tutor</td>\n",
       "      <td>[[0.025888918, -0.05742222, -0.053885072, 0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Gel nail</td>\n",
       "      <td>[[-0.040884357, 0.06660764, -0.039469324, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Custom Love Song üòçüòçüòç</td>\n",
       "      <td>[[0.05952203, -0.06517673, -0.019530311, 0.083...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>Metal Shop Cleaner</td>\n",
       "      <td>[[-0.049536776, 0.03874949, -0.013470527, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Hand stitched coasters</td>\n",
       "      <td>[[-0.0183809, -0.008090916, -0.01526901, 0.072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Economist Notebook</td>\n",
       "      <td>[[0.04645348, 0.005017322, -0.030449953, 0.070...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Model Making Help</td>\n",
       "      <td>[[0.042392638, 0.070980184, 0.05112772, 0.0636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Golf Lessons</td>\n",
       "      <td>[[0.03161938, 0.03469069, 0.069884874, -0.0085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Help Frame Two Canvas Paintings!</td>\n",
       "      <td>[[0.007955755, 0.05891502, -0.009488564, 0.019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Dinner</td>\n",
       "      <td>[[-0.020769225, -0.02868131, -0.050769217, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>LET ME VIDEOGRAPHY YOU DOING SOMETHING COOL</td>\n",
       "      <td>[[0.058810335, 0.050573807, 0.023708878, 0.080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Biking Lessons</td>\n",
       "      <td>[[0.03248001, -0.006866291, 0.064346954, 0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Running Partner</td>\n",
       "      <td>[[0.012574943, -0.03078693, -0.022168757, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Grocery Runs</td>\n",
       "      <td>[[-0.029154377, 0.08117728, -0.1252381, 0.0942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Parking Spot</td>\n",
       "      <td>[[-0.0006021084, 0.013624414, -0.0066231927, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Ethernet Cable</td>\n",
       "      <td>[[-0.036790896, 0.020264264, -0.016886886, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Steve Madden Heel Booties</td>\n",
       "      <td>[[-0.017656269, -0.023403468, -0.0788021, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Wordsmith</td>\n",
       "      <td>[[0.05720999, -0.011893656, 0.029809417, 0.075...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>Brazilian Cooking Class</td>\n",
       "      <td>[[-0.09709267, 0.04692349, 0.031251416, 0.0841...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Iron</td>\n",
       "      <td>[[-0.01914381, 0.041911554, 0.05451653, -0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Sneaker Shopping</td>\n",
       "      <td>[[0.04779238, 0.051733505, -0.050037324, 0.114...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Dogsitter</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Photographer Wanted</td>\n",
       "      <td>[[0.041132804, 0.055709932, 0.00022233947, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Ukulele Lessons</td>\n",
       "      <td>[[0.061797857, -0.00044781057, 0.055618074, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Marketing Advice</td>\n",
       "      <td>[[0.01688988, -0.03561996, -0.05343707, -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Looking For Graphic Design</td>\n",
       "      <td>[[-0.010068101, 0.039581455, 0.026983991, 0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Titles  \\\n",
       "0                       Corporate Finance Tutor    \n",
       "1                                     R Tutoring   \n",
       "2         Help Setting up for Farmers Market Sun   \n",
       "3                Bak-Tang-Wiesenfeld Model Appl.   \n",
       "4                          Feedback (re: Pangea)   \n",
       "5                                 Recital Poster   \n",
       "6                           Beautycounter Social   \n",
       "7                                Solidworks Help   \n",
       "8                              Homecooked Dinner   \n",
       "9                                 Food delivery!   \n",
       "10                          Video making lessons   \n",
       "11                               Pokemon lets go   \n",
       "12                    Behavioral Interview Prep    \n",
       "13                        Farm Fresh Meal Prep!    \n",
       "14                              Personal Trainer   \n",
       "15                      Film shoot participants!   \n",
       "16                                    Dogsitting   \n",
       "17                                    Life Coach   \n",
       "18                                        cs hw    \n",
       "19                                Metal machine    \n",
       "20                                     BONEYARDS   \n",
       "21                                   Translation   \n",
       "22                                         Lamp    \n",
       "23                                     ID Friend   \n",
       "24                                   Photography   \n",
       "25                                        Jeenne   \n",
       "26                                  Bike lessons   \n",
       "27                                     Your man    \n",
       "28                                   Foam Models   \n",
       "29                       Social Media Management   \n",
       "..                                           ...   \n",
       "711                       Zero Waste Pop Up Shop   \n",
       "712                        Selling Galaxy Note 2   \n",
       "713                              French tutoring   \n",
       "714                      Board Games! (Teaching)   \n",
       "715                              SAS / SQL Tutor   \n",
       "716                                     Gel nail   \n",
       "717                         Custom Love Song üòçüòçüòç   \n",
       "718                           Metal Shop Cleaner   \n",
       "719                       Hand stitched coasters   \n",
       "720                           Economist Notebook   \n",
       "721                            Model Making Help   \n",
       "722                                 Golf Lessons   \n",
       "723            Help Frame Two Canvas Paintings!    \n",
       "724                                       Dinner   \n",
       "725  LET ME VIDEOGRAPHY YOU DOING SOMETHING COOL   \n",
       "726                              Biking Lessons    \n",
       "727                              Running Partner   \n",
       "728                                 Grocery Runs   \n",
       "729                                 Parking Spot   \n",
       "730                               Ethernet Cable   \n",
       "731                    Steve Madden Heel Booties   \n",
       "732                                   Wordsmith    \n",
       "733                      Brazilian Cooking Class   \n",
       "734                                         Iron   \n",
       "735                            Sneaker Shopping    \n",
       "736                                    Dogsitter   \n",
       "737                          Photographer Wanted   \n",
       "738                              Ukulele Lessons   \n",
       "739                             Marketing Advice   \n",
       "740                  Looking For Graphic Design    \n",
       "\n",
       "                                               Vectors  \n",
       "0    [[0.009595259, 0.0074430513, -0.050515227, 0.0...  \n",
       "1    [[-0.0508224, 0.11041136, -0.016052296, 0.1061...  \n",
       "2    [[0.0017549094, 0.07764145, -0.04477678, 0.018...  \n",
       "3    [[0.07684814, 0.05254751, 0.03842407, 0.088479...  \n",
       "4    [[-0.06494846, -0.00715124, -0.04504936, -0.04...  \n",
       "5    [[0.057445057, 0.024767978, 0.0071285986, 0.03...  \n",
       "6    [[0.039335, -0.038753696, -0.049023423, 0.0647...  \n",
       "7    [[0.011597187, 0.06816306, -0.061062742, 0.136...  \n",
       "8    [[-0.046437792, -0.011173413, -0.012645033, 0....  \n",
       "9    [[-0.06801747, 0.06180082, -0.062166505, 0.133...  \n",
       "10   [[0.017601628, 0.041898996, 0.046152107, -0.00...  \n",
       "11   [[0.008599127, 0.025929207, 0.04041995, 0.0909...  \n",
       "12   [[-0.03956067, 0.072352774, -0.069752164, 0.03...  \n",
       "13   [[-0.032631777, 0.014317139, 0.014599571, 0.08...  \n",
       "14   [[0.02932334, -0.014871498, 0.005665332, -0.02...  \n",
       "15   [[0.032354895, 0.009640244, -0.012234643, 0.07...  \n",
       "16   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "17   [[-0.030054724, 0.043134633, 0.07173603, 0.006...  \n",
       "18   [[-0.09039003, 0.042158194, 0.058458764, 0.034...  \n",
       "19   [[0.016601164, 0.030331235, -0.025981957, 0.01...  \n",
       "20   [[0.05402433, 0.117187105, 0.023383666, 0.0631...  \n",
       "21   [[-0.014843704, -0.0070974, -0.005008736, 0.02...  \n",
       "22   [[-0.00524103, 0.06696872, -0.020381782, 0.020...  \n",
       "23   [[0.08986307, -0.08230449, 0.037840683, 0.0773...  \n",
       "24   [[0.0005714418, 0.017823197, -0.026233276, 0.0...  \n",
       "25   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "26   [[0.020154754, 0.020881988, 0.053399708, 0.036...  \n",
       "27   [[0.14116225, 0.056633953, 0.0150037715, -0.03...  \n",
       "28   [[0.0032934858, 0.040808346, 0.016673272, 0.06...  \n",
       "29   [[0.008659906, -0.0006811162, -0.09584278, -0....  \n",
       "..                                                 ...  \n",
       "711  [[-0.0057765376, 0.05752307, 0.058385674, 0.14...  \n",
       "712  [[0.022602776, 0.12781008, -0.06594746, -0.006...  \n",
       "713  [[0.011164687, 0.07357873, 0.06452894, 0.15856...  \n",
       "714  [[-0.058998547, -0.10603793, -0.0065775407, -0...  \n",
       "715  [[0.025888918, -0.05742222, -0.053885072, 0.06...  \n",
       "716  [[-0.040884357, 0.06660764, -0.039469324, -0.1...  \n",
       "717  [[0.05952203, -0.06517673, -0.019530311, 0.083...  \n",
       "718  [[-0.049536776, 0.03874949, -0.013470527, 0.03...  \n",
       "719  [[-0.0183809, -0.008090916, -0.01526901, 0.072...  \n",
       "720  [[0.04645348, 0.005017322, -0.030449953, 0.070...  \n",
       "721  [[0.042392638, 0.070980184, 0.05112772, 0.0636...  \n",
       "722  [[0.03161938, 0.03469069, 0.069884874, -0.0085...  \n",
       "723  [[0.007955755, 0.05891502, -0.009488564, 0.019...  \n",
       "724  [[-0.020769225, -0.02868131, -0.050769217, 0.1...  \n",
       "725  [[0.058810335, 0.050573807, 0.023708878, 0.080...  \n",
       "726  [[0.03248001, -0.006866291, 0.064346954, 0.040...  \n",
       "727  [[0.012574943, -0.03078693, -0.022168757, 0.01...  \n",
       "728  [[-0.029154377, 0.08117728, -0.1252381, 0.0942...  \n",
       "729  [[-0.0006021084, 0.013624414, -0.0066231927, -...  \n",
       "730  [[-0.036790896, 0.020264264, -0.016886886, 0.0...  \n",
       "731  [[-0.017656269, -0.023403468, -0.0788021, 0.12...  \n",
       "732  [[0.05720999, -0.011893656, 0.029809417, 0.075...  \n",
       "733  [[-0.09709267, 0.04692349, 0.031251416, 0.0841...  \n",
       "734  [[-0.01914381, 0.041911554, 0.05451653, -0.022...  \n",
       "735  [[0.04779238, 0.051733505, -0.050037324, 0.114...  \n",
       "736  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "737  [[0.041132804, 0.055709932, 0.00022233947, -0....  \n",
       "738  [[0.061797857, -0.00044781057, 0.055618074, 0....  \n",
       "739  [[0.01688988, -0.03561996, -0.05343707, -0.020...  \n",
       "740  [[-0.010068101, 0.039581455, 0.026983991, 0.02...  \n",
       "\n",
       "[741 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Print a dataframe to show how these titles and their vectors will be saved''''\n",
    "'''Also note that we are saving the df with the original raw (not cleaned) titles'''\n",
    "vectorize_and_store_existing_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read a JSON file when a new user pings with a request'''\n",
    "with open('firstPost.json') as fresh_data:\n",
    "    user_post = json.load(fresh_data)\n",
    "\n",
    "'''Vectorize each new title as a user/student/company creates a new post'''\n",
    "def vectorize_new_title(user_post):\n",
    "    #ranked_titles_load = pd.read_csv(\"./ranked_titles.csv\")\n",
    "    json_df = pd.DataFrame.from_dict(json_normalize(user_post), orient='columns')\n",
    "    title = json_df[\"title\"][0] #--> added [0] because json_df[\"title\"] was still in pd.Series form\n",
    "    json_tokens = [word for word in title.lower().split()]\n",
    "    json_clean_words = [word for word in json_tokens if word.isalpha()]\n",
    "    stoplist = set(stopwords.words('english'));\n",
    "    json_titles_nostopwords = [word for word in json_clean_words if word not in stoplist]   \n",
    "    json_preprocessed = [word for word in json_titles_nostopwords if word in model.vocab]   \n",
    "    json_title_vectors = {}\n",
    "    json_vectorized_title_df = pd.DataFrame(columns=[\"Titles\", \"Vectors\"])\n",
    "    json_word_vecs = [model[word] for word in json_preprocessed]\n",
    "    if len(json_preprocessed) == 0:\n",
    "            json_title_vec = [np.zeros(300)]\n",
    "    else: \n",
    "        json_title_vec = normalize(sum(json_word_vecs).reshape(1, -1))\n",
    "    json_vectorized_title_df = json_vectorized_title_df.append({'Titles': title, 'Vectors': json_title_vec}, ignore_index = True)\n",
    "    #export_csv = json_vectorized_title_df.to_csv (r'/Users/angelateng/Dropbox/AMBER/SharpestMinds/ranked_titles.csv', index = None, header=True) #Don't forget to add '.csv' at the end of the path\n",
    "    if not os.path.isfile('/Users/angelateng/Dropbox/AMBER/SharpestMinds/ranked_titles.csv'):\n",
    "        json_vectorized_title_df.to_csv (r'/Users/angelateng/Dropbox/AMBER/SharpestMinds/ranked_titles.csv', index = None, header=True)\n",
    "    else:\n",
    "        json_vectorized_title_df.to_csv (r'/Users/angelateng/Dropbox/AMBER/SharpestMinds/ranked_titles.csv', mode='a', index = None, header=False)\n",
    "    \n",
    "    return(json_vectorized_title_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Titles                                            Vectors\n",
      "0  Teach Me How To Cook!  [[0.042356346, -0.013683017, 0.07774045, 0.028...\n"
     ]
    }
   ],
   "source": [
    "'''Append new user-post title to csv'''\n",
    "vectorized_title = vectorize_new_title(user_post)\n",
    "print(vectorized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def rank_existing_titles(vectorized_title):\n",
    "    #loop over all keys in dict \n",
    "    ranked_titles = {}\n",
    "    other_titles = pd.read_pickle(\"./vectorized_titles.pkl\")\n",
    "    for index,row in other_titles.iterrows():\n",
    "        ranked_titles[row['Titles']] = sum(row['Vectors'][0]*vectorized_title['Vectors'][0][0]) # --> did the dot product using sum() and * because np.dot was behaving weirdly for some reason. Now it seems to work! \n",
    "    sorted_title_vecs = sorted(ranked_titles.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return(sorted_title_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(user_post):\n",
    "    title = user_post[\"title\"]\n",
    "    vectorized_title = vectorize_new_title(user_post)\n",
    "\n",
    "    ranked_titles = rank_existing_titles(vectorized_title)\n",
    "    \n",
    "    with open(\"./ranked_titles.csv\", \"w\", newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for title in ranked_titles:\n",
    "            wr.writerow([ranked_titles, title])\n",
    "    return(ranked_titles)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(generate_recommendations(user_post))\n",
    "df.columns = [\"Title\", \"Similarity Score\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_recommendations(json_df)\n",
    "pprint(generate_recommendations(user_post))\n",
    "type(generate_recommendations(user_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
