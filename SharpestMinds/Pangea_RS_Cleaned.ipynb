{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System - Marketplace Matching\n",
    "\n",
    "In this notebook, we will: \n",
    "- Clean textual data from user-input verbatim posts\n",
    "- Use a Word2Vec model to calculate document similarities \n",
    "- Sort the most similar user input to our training data in order to recommend similar products \n",
    "- Save this model in a format that allows us to refresh the testing data\n",
    "\n",
    "The goal of this project is to create a recommender system to help Pangeans find the right \"project\" for them, given their profile information. Here, we are using legacy data that is from Pangea V2, when Pangeans were allowed to post services and requests, as well as purchase items on the platform. We are using the User-Inputted Titles to suggest similar services, or in V3, similar \"projects\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/angelateng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "from pandas import DataFrame\n",
    "\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from gensim import corpora\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords') ###\n",
    "\n",
    "import gensim \n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "\n",
    "from operator import itemgetter, attrgetter\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "import os, sys\n",
    "\n",
    "from operator import add\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from adjustText import adjust_text\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import pickle\n",
    "\n",
    "import json\n",
    "from pprint import pprint\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "import operator\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def vectorize_and_store_existing_titles():\n",
    "    \n",
    "    raw = pd.read_csv(\"allPostData.csv\", header=0);\n",
    "    \n",
    "    #we can replace this with a filepath in the future\n",
    "    titles = raw['title'];\n",
    "    post_titles = [title for title in titles];\n",
    "    post_titles = set(post_titles);\n",
    "    \n",
    "    tokens = [[word for word in title.lower().split()] for title in post_titles];\n",
    "    \n",
    "    clean_words = [[word for word in title if word.isalpha()] for title in tokens];\n",
    "    stoplist = set(stopwords.words('english'));\n",
    "    \n",
    "    titles_nostopwords = [[word for word in title if word not in stoplist] for title in clean_words];   \n",
    "    #print(len(titles_nostopwords))\n",
    "    \n",
    "    filtered_word_list = [[word for word in title if word in model.vocab] for title in titles_nostopwords];\n",
    "    #print(len(filtered_word_list))\n",
    "    \n",
    "    dictionary = dict(zip(post_titles, filtered_word_list))\n",
    "    \n",
    "    title_vectors = {}\n",
    "    \n",
    "    #print(len(dictionary.keys()))\n",
    "    \n",
    "    #print(len(set(titles)))\n",
    "    #print(len(set(post_titles)))\n",
    "    #dupe reqs \n",
    "    \n",
    "    vectorized_titles = pd.DataFrame(columns=[\"Titles\", \"Vectors\"])\n",
    "    print(vectorized_titles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for title in post_titles: \n",
    "        word_vecs = [model[word] for word in dictionary[title]]\n",
    "        if len(word_vecs) == 0:\n",
    "            title_vec = [np.zeros(300)]\n",
    "        else: \n",
    "            title_vec = normalize(sum(word_vecs).reshape(1, -1))\n",
    "       \n",
    "        vectorized_titles = vectorized_titles.append({'Titles': title, 'Vectors': title_vec}, ignore_index=True)\n",
    "       \n",
    "    \n",
    "    \n",
    "    #dictionary = dict(zip(post_titles, filtered_word_list))\n",
    "\n",
    "    #can also replace filepath in the future\n",
    "    #titles.to_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/raw_titles.pkl\")\n",
    "    vectorized_titles.to_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/vectorized_titles.pkl\")\n",
    "    return(vectorized_titles)\n",
    "\n",
    "#vectorize_and_store_existing_titles()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hang up my TV mount</td>\n",
       "      <td>[[-0.044453368, 0.044327557, -0.11491825, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fantasy Football Consulting</td>\n",
       "      <td>[[0.039403234, -0.016861744, 0.049298417, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Make Brandy Alexander Pie</td>\n",
       "      <td>[[-0.072663724, -0.06542867, 0.011346995, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photographer Wanted</td>\n",
       "      <td>[[0.041132804, 0.055709932, 0.00022233947, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soccer Lessons</td>\n",
       "      <td>[[0.020405818, 0.049692925, 0.13152766, -0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Please Buy Me A Ben &amp; Jerry’s Ice Cream Cake!!!</td>\n",
       "      <td>[[-0.04161577, 0.041488077, 0.034238372, 0.043...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Marketing Advice</td>\n",
       "      <td>[[0.01688988, -0.03561996, -0.05343707, -0.020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Power Drill</td>\n",
       "      <td>[[0.0013474241, 0.022457069, 0.057462025, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Software Engineer needed for small proj</td>\n",
       "      <td>[[0.001173173, 0.013858106, -0.013720624, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Postering</td>\n",
       "      <td>[[0.02030486, 0.011536853, 0.0025765637, 0.047...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Research Buddy</td>\n",
       "      <td>[[-0.033732753, -0.053159453, -0.0073673795, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Acting Lessons</td>\n",
       "      <td>[[0.031968884, 0.03987578, 0.037088457, -0.074...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Spanish Tutor</td>\n",
       "      <td>[[-0.013885816, -0.07959897, -0.00063561834, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>HTML email deisgn</td>\n",
       "      <td>[[0.0036273915, -0.005392332, -0.019853143, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Beat making</td>\n",
       "      <td>[[-0.015095135, 0.100170486, 0.09196207, -0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Grocery Runs</td>\n",
       "      <td>[[-0.029154377, 0.08117728, -0.1252381, 0.0942...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>will to live</td>\n",
       "      <td>[[0.0070651565, 0.007217642, -0.017383335, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Make cookies</td>\n",
       "      <td>[[-0.035415158, -0.04511013, 0.01420028, 0.153...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Teach me how to play piano</td>\n",
       "      <td>[[0.049140893, -0.025723236, 0.03730283, 0.011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Pattern maker</td>\n",
       "      <td>[[0.04902173, -0.022968967, -0.012760537, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Web Development</td>\n",
       "      <td>[[-0.0029527857, -0.02281698, -0.027011279, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pet Photography</td>\n",
       "      <td>[[0.008165506, 0.047769435, -0.055339456, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Meal Credit</td>\n",
       "      <td>[[-0.052851856, 0.040494706, -0.020219522, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Printer</td>\n",
       "      <td>[[0.04149142, 0.004927106, -0.07290635, 0.0806...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Editorial Photographer</td>\n",
       "      <td>[[-0.027437793, -0.016791126, -0.11868857, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Ride In A Porsche Cayenne</td>\n",
       "      <td>[[0.033785403, -0.031169875, 0.04166806, 0.049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Search Engine Optimizatio</td>\n",
       "      <td>[[0.10572288, 0.0032037236, -0.035347752, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Solidworks Help</td>\n",
       "      <td>[[0.011597187, 0.06816306, -0.061062742, 0.136...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Teach how to prepare steaks</td>\n",
       "      <td>[[-0.019265316, 0.05949351, 0.033734042, 0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Help hanging lights in my common room</td>\n",
       "      <td>[[0.042535964, 0.07817348, 0.030671706, 0.0581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Proofreading/Editing</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>French Lessons</td>\n",
       "      <td>[[0.028141204, 0.045595877, 0.12620287, 0.0805...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>Programming Advise</td>\n",
       "      <td>[[-0.08503098, -0.0038664015, 0.064609215, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Materials engineer</td>\n",
       "      <td>[[0.0067553753, 0.031734552, 0.027728459, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>Cooking lessons</td>\n",
       "      <td>[[0.006142837, 0.078218795, 0.064192645, 0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>Hitting lessons</td>\n",
       "      <td>[[0.040414438, 0.07092595, 0.06649308, -0.0150...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>Haircuts for men and women</td>\n",
       "      <td>[[-0.038895812, 0.08543946, 0.02943258, 0.0581...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>CS Tutor</td>\n",
       "      <td>[[-0.026808849, 0.018503362, 0.04615327, 0.039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>Smash 64 Practice</td>\n",
       "      <td>[[0.062727526, 0.018316587, -0.04743604, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Seasonal Photos</td>\n",
       "      <td>[[-0.033861738, 0.101302564, -0.06048758, 0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Highschool Math</td>\n",
       "      <td>[[0.03829625, -0.0052716443, 0.069784276, 0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Spanish tutoring</td>\n",
       "      <td>[[-0.0044827247, -0.00971257, 0.0032219584, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>Model Making Help</td>\n",
       "      <td>[[0.042392638, 0.070980184, 0.05112772, 0.0636...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Ballroom dancing lessons</td>\n",
       "      <td>[[0.047794234, -0.031833734, 0.07476739, 0.015...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>Make me waffles</td>\n",
       "      <td>[[-0.10263428, -0.06991653, 0.046897482, 0.109...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>Fix Zipper</td>\n",
       "      <td>[[-0.014315493, 0.0018566606, -0.019975107, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>Cooking</td>\n",
       "      <td>[[-0.04758457, 0.08532406, 0.017557066, 0.0429...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>Rest. Review Partner</td>\n",
       "      <td>[[-0.15995777, -0.07392415, -0.03048491, 0.036...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>Change Lower Control Arms to Car</td>\n",
       "      <td>[[0.018707616, 0.002507028, 0.0033542307, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>Learn To Harmonize</td>\n",
       "      <td>[[-0.03326536, -0.0058446107, -0.021009702, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Melee Practice Partner</td>\n",
       "      <td>[[0.09075975, -0.024231423, -0.0005425578, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>Poster design</td>\n",
       "      <td>[[-0.03296833, 0.041975748, 0.005622278, 0.060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>tennis stringing</td>\n",
       "      <td>[[-0.07873873, 0.025344653, -0.0038067068, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Stickers needed</td>\n",
       "      <td>[[0.0613278, 0.027393484, 0.010426326, 0.02688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>Family portrait</td>\n",
       "      <td>[[0.04924191, 0.015757412, -0.07360962, 0.0505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>Personal pet for a day</td>\n",
       "      <td>[[0.015168878, 0.05263752, -0.04207978, 0.0673...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>Graphic Designer</td>\n",
       "      <td>[[0.03184493, -0.07139856, -0.047461703, 0.058...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Jam session</td>\n",
       "      <td>[[0.029015118, -0.012569726, -0.05792549, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>[[-0.009190964, -0.003567433, 0.00986245, 0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>Spanish Tutoring</td>\n",
       "      <td>[[-0.0044827247, -0.00971257, 0.0032219584, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>741 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Titles  \\\n",
       "0                                hang up my TV mount   \n",
       "1                        Fantasy Football Consulting   \n",
       "2                          Make Brandy Alexander Pie   \n",
       "3                                Photographer Wanted   \n",
       "4                                     Soccer Lessons   \n",
       "5    Please Buy Me A Ben & Jerry’s Ice Cream Cake!!!   \n",
       "6                                   Marketing Advice   \n",
       "7                                       Power Drill    \n",
       "8            Software Engineer needed for small proj   \n",
       "9                                          Postering   \n",
       "10                                    Research Buddy   \n",
       "11                                    Acting Lessons   \n",
       "12                                    Spanish Tutor    \n",
       "13                                 HTML email deisgn   \n",
       "14                                       Beat making   \n",
       "15                                      Grocery Runs   \n",
       "16                                      will to live   \n",
       "17                                      Make cookies   \n",
       "18                        Teach me how to play piano   \n",
       "19                                     Pattern maker   \n",
       "20                                   Web Development   \n",
       "21                                  Pet Photography    \n",
       "22                                       Meal Credit   \n",
       "23                                           Printer   \n",
       "24                            Editorial Photographer   \n",
       "25                         Ride In A Porsche Cayenne   \n",
       "26                         Search Engine Optimizatio   \n",
       "27                                   Solidworks Help   \n",
       "28                      Teach how to prepare steaks    \n",
       "29             Help hanging lights in my common room   \n",
       "..                                               ...   \n",
       "711                             Proofreading/Editing   \n",
       "712                                   French Lessons   \n",
       "713                               Programming Advise   \n",
       "714                              Materials engineer    \n",
       "715                                  Cooking lessons   \n",
       "716                                 Hitting lessons    \n",
       "717                      Haircuts for men and women    \n",
       "718                                         CS Tutor   \n",
       "719                                Smash 64 Practice   \n",
       "720                                  Seasonal Photos   \n",
       "721                                  Highschool Math   \n",
       "722                                Spanish tutoring    \n",
       "723                                Model Making Help   \n",
       "724                         Ballroom dancing lessons   \n",
       "725                                  Make me waffles   \n",
       "726                                       Fix Zipper   \n",
       "727                                          Cooking   \n",
       "728                             Rest. Review Partner   \n",
       "729                 Change Lower Control Arms to Car   \n",
       "730                               Learn To Harmonize   \n",
       "731                           Melee Practice Partner   \n",
       "732                                    Poster design   \n",
       "733                                tennis stringing    \n",
       "734                                  Stickers needed   \n",
       "735                                  Family portrait   \n",
       "736                          Personal pet for a day    \n",
       "737                                Graphic Designer    \n",
       "738                                     Jam session    \n",
       "739                              Data Science Intern   \n",
       "740                                 Spanish Tutoring   \n",
       "\n",
       "                                               Vectors  \n",
       "0    [[-0.044453368, 0.044327557, -0.11491825, 0.04...  \n",
       "1    [[0.039403234, -0.016861744, 0.049298417, 0.00...  \n",
       "2    [[-0.072663724, -0.06542867, 0.011346995, 0.08...  \n",
       "3    [[0.041132804, 0.055709932, 0.00022233947, -0....  \n",
       "4    [[0.020405818, 0.049692925, 0.13152766, -0.036...  \n",
       "5    [[-0.04161577, 0.041488077, 0.034238372, 0.043...  \n",
       "6    [[0.01688988, -0.03561996, -0.05343707, -0.020...  \n",
       "7    [[0.0013474241, 0.022457069, 0.057462025, -0.0...  \n",
       "8    [[0.001173173, 0.013858106, -0.013720624, -0.0...  \n",
       "9    [[0.02030486, 0.011536853, 0.0025765637, 0.047...  \n",
       "10   [[-0.033732753, -0.053159453, -0.0073673795, 0...  \n",
       "11   [[0.031968884, 0.03987578, 0.037088457, -0.074...  \n",
       "12   [[-0.013885816, -0.07959897, -0.00063561834, 0...  \n",
       "13   [[0.0036273915, -0.005392332, -0.019853143, 0....  \n",
       "14   [[-0.015095135, 0.100170486, 0.09196207, -0.03...  \n",
       "15   [[-0.029154377, 0.08117728, -0.1252381, 0.0942...  \n",
       "16   [[0.0070651565, 0.007217642, -0.017383335, 0.0...  \n",
       "17   [[-0.035415158, -0.04511013, 0.01420028, 0.153...  \n",
       "18   [[0.049140893, -0.025723236, 0.03730283, 0.011...  \n",
       "19   [[0.04902173, -0.022968967, -0.012760537, 0.11...  \n",
       "20   [[-0.0029527857, -0.02281698, -0.027011279, -0...  \n",
       "21   [[0.008165506, 0.047769435, -0.055339456, 0.04...  \n",
       "22   [[-0.052851856, 0.040494706, -0.020219522, 0.1...  \n",
       "23   [[0.04149142, 0.004927106, -0.07290635, 0.0806...  \n",
       "24   [[-0.027437793, -0.016791126, -0.11868857, 0.0...  \n",
       "25   [[0.033785403, -0.031169875, 0.04166806, 0.049...  \n",
       "26   [[0.10572288, 0.0032037236, -0.035347752, -0.0...  \n",
       "27   [[0.011597187, 0.06816306, -0.061062742, 0.136...  \n",
       "28   [[-0.019265316, 0.05949351, 0.033734042, 0.022...  \n",
       "29   [[0.042535964, 0.07817348, 0.030671706, 0.0581...  \n",
       "..                                                 ...  \n",
       "711  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  \n",
       "712  [[0.028141204, 0.045595877, 0.12620287, 0.0805...  \n",
       "713  [[-0.08503098, -0.0038664015, 0.064609215, 0.0...  \n",
       "714  [[0.0067553753, 0.031734552, 0.027728459, -0.0...  \n",
       "715  [[0.006142837, 0.078218795, 0.064192645, 0.008...  \n",
       "716  [[0.040414438, 0.07092595, 0.06649308, -0.0150...  \n",
       "717  [[-0.038895812, 0.08543946, 0.02943258, 0.0581...  \n",
       "718  [[-0.026808849, 0.018503362, 0.04615327, 0.039...  \n",
       "719  [[0.062727526, 0.018316587, -0.04743604, -0.00...  \n",
       "720  [[-0.033861738, 0.101302564, -0.06048758, 0.07...  \n",
       "721  [[0.03829625, -0.0052716443, 0.069784276, 0.09...  \n",
       "722  [[-0.0044827247, -0.00971257, 0.0032219584, 0....  \n",
       "723  [[0.042392638, 0.070980184, 0.05112772, 0.0636...  \n",
       "724  [[0.047794234, -0.031833734, 0.07476739, 0.015...  \n",
       "725  [[-0.10263428, -0.06991653, 0.046897482, 0.109...  \n",
       "726  [[-0.014315493, 0.0018566606, -0.019975107, 0....  \n",
       "727  [[-0.04758457, 0.08532406, 0.017557066, 0.0429...  \n",
       "728  [[-0.15995777, -0.07392415, -0.03048491, 0.036...  \n",
       "729  [[0.018707616, 0.002507028, 0.0033542307, 0.05...  \n",
       "730  [[-0.03326536, -0.0058446107, -0.021009702, 0....  \n",
       "731  [[0.09075975, -0.024231423, -0.0005425578, -0....  \n",
       "732  [[-0.03296833, 0.041975748, 0.005622278, 0.060...  \n",
       "733  [[-0.07873873, 0.025344653, -0.0038067068, 0.0...  \n",
       "734  [[0.0613278, 0.027393484, 0.010426326, 0.02688...  \n",
       "735  [[0.04924191, 0.015757412, -0.07360962, 0.0505...  \n",
       "736  [[0.015168878, 0.05263752, -0.04207978, 0.0673...  \n",
       "737  [[0.03184493, -0.07139856, -0.047461703, 0.058...  \n",
       "738  [[0.029015118, -0.012569726, -0.05792549, 0.12...  \n",
       "739  [[-0.009190964, -0.003567433, 0.00986245, 0.04...  \n",
       "740  [[-0.0044827247, -0.00971257, 0.0032219584, 0....  \n",
       "\n",
       "[741 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/vectorized_titles.pkl\")\n",
    "#sanity check\n",
    "#vectorize_and_store_existing_titles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can change this directory later\n",
    "\n",
    "\n",
    "#test post \n",
    "with open('firstPost.json') as fresh_data:\n",
    "    user_post = json.load(fresh_data)\n",
    "\n",
    "#user_post = json.loads('firstPost.json')\n",
    "#print(user_post)\n",
    "\n",
    "#should only take in a single post at a time \n",
    "\n",
    "def vectorize_new_title(user_post):\n",
    "    json_df = pd.DataFrame.from_dict(json_normalize(user_post), orient='columns')\n",
    "    #print(json_df)\n",
    "    \n",
    "    title = json_df[\"title\"]\n",
    "    #print(\"this is the title\", title)\n",
    "    \n",
    "    #json_post_titles = [title in title];\n",
    "    json_post_titles = [title for title in title];\n",
    "    json_tokens = [[word for word in title.lower().split()] for title in json_post_titles];\n",
    "    #json_post_titles = set(json_post_titles)\n",
    "    print(json_post_titles)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #json_clean_words = [[word for word in title if word.isalpha()] for title in json_post_titles];\n",
    "    json_clean_words = [[word for word in title if word.isalpha()] for title in json_tokens];\n",
    "    print(json_clean_words)\n",
    "    \n",
    "    stoplist = set(stopwords.words('english'));\n",
    "    json_titles_nostopwords = [[word for word in title if word not in stoplist] for title in json_clean_words];   \n",
    "    \n",
    "    \n",
    "    json_filtered_word_list = [[word for word in title if word in model.vocab] for title in json_titles_nostopwords];\n",
    "    print(json_filtered_word_list)\n",
    "    \n",
    "    json_title_vectors = {}\n",
    "    \n",
    "    json_vectorized_titles = pd.DataFrame(columns=[\"Titles\", \"Vectors\"])\n",
    "    print(json_vectorized_titles)\n",
    "    \n",
    "    \n",
    "    for title in json_filtered_word_list: \n",
    "        json_word_vecs = [model[word] for word in title]\n",
    "        if len(json_word_vecs) == 0:\n",
    "            json_title_vec = [np.zeros(300)]\n",
    "        else: \n",
    "            json_title_vec = normalize(sum(json_word_vecs).reshape(1, -1))\n",
    "        \n",
    "        json_vectorized_titles = json_vectorized_titles.append({'Titles': title, 'Vectors': json_title_vec}, ignore_index=True)\n",
    "   \n",
    "\n",
    "    return(json_vectorized_titles)\n",
    "\n",
    "#vectorize_new_title(json_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Teach Me How To Cook!']\n",
      "[['teach', 'me', 'how', 'to']]\n",
      "[['teach']]\n",
      "Empty DataFrame\n",
      "Columns: [Titles, Vectors]\n",
      "Index: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "      <th>Vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[teach]</td>\n",
       "      <td>[[0.042356346, -0.013683017, 0.07774045, 0.028...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Titles                                            Vectors\n",
       "0  [teach]  [[0.042356346, -0.013683017, 0.07774045, 0.028..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize_new_title(user_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_title = vectorize_new_title(user_post)\n",
    "\n",
    "def rank_existing_titles(vectorized_title):\n",
    "    #loop over all keys in dict \n",
    "    ranked_titles = {}\n",
    "    other_titles = pd.read_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/raw_titles.pkl\")\n",
    "    #other_titles = pd.read_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/vectorized_titles.pkl\")\n",
    "    #can also use title_vectors.keys() \n",
    "    for title in other_titles:\n",
    "        #ranked_titles[title] = np.dot(other_titles[title], vectorized_title)[0]\n",
    "        ranked_titles[title] = np.dot(other_titles, vectorized_title)[0]\n",
    "    #print(other_titles)\n",
    "        #print(np.dot(other_titles[title], vectorized_title))\n",
    "    sorted_title_vecs = sorted(ranked_titles.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #print(sorted_title_vecs)\n",
    "    #dicts not ordered \n",
    "    return(sorted_title_vecs)\n",
    "\n",
    "#rank_existing_titles(vectorized_title[:10])\n",
    "#word querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (811,) and (300,1) not aligned: 811 (dim 0) != 300 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-04450f3d040d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrank_existing_titles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-ce28d79051e9>\u001b[0m in \u001b[0;36mrank_existing_titles\u001b[0;34m(vectorized_title)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mother_titles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#ranked_titles[title] = np.dot(other_titles[title], vectorized_title)[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mranked_titles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_titles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorized_title\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#print(other_titles)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m#print(np.dot(other_titles[title], vectorized_title))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (811,) and (300,1) not aligned: 811 (dim 0) != 300 (dim 0)"
     ]
    }
   ],
   "source": [
    "rank_existing_titles(vectorized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_titles = pd.read_pickle(\"/Users/angelateng/Dropbox/SharpestMinds/raw_titles.pkl\")\n",
    "other_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_title = vectorize_new_title(user_post)\n",
    "print(vectorized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(user_post):\n",
    "    title = user_post[\"title\"]\n",
    "    print(title)\n",
    "    vectorized_title = vectorize_new_title(user_post)\n",
    "    print(vectorized_title)\n",
    "    ranked_titles = rank_existing_titles(title, vectorized_title)\n",
    "    print(ranked_titles)\n",
    "    \n",
    "    \n",
    "    with open(\"/Users/angelateng/Dropbox/SharpestMinds/ranked_titles.csv\", \"w\", newline='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for title in ranked_titles:\n",
    "            wr.writerow([ranked_titles, title])\n",
    "    #csv_out = ranked_titles.to_csv('ranked_titles', encoding='utf-8', index=False)\n",
    "    #writer = csv.writer(ranked_titles, delimiter='', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    " \n",
    "    #for row in reader:\n",
    "        #writer.writerow(row)\n",
    "\n",
    "       # with open('csv_out', 'wb') as csv_out:\n",
    "         #   csv_writer = csv.writer(csv_out, quoting=csv.QUOTE_ALL)\n",
    "         #   csv_writer.writerow('csv_out')\n",
    "    return(ranked_titles)\n",
    "    \n",
    "    \n",
    "\n",
    "#vectorize_and_store_existing_titles(); \n",
    "#vectorize_new_title(json_df);\n",
    "#rank_existing_titles(vectorize_new_title);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_recommendations(json_df)\n",
    "pprint(generate_recommendations(user_post))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(other_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
